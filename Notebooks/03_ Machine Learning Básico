import tensorflow as tf
print("GPU disponible:", tf.config.list_physical_devices('GPU'))

!pip install seaborn plotly -q

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    mean_squared_error, r2_score
)
import warnings
warnings.filterwarnings('ignore')

plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

print("Entorno configurado correctamente en Google Colab")

     
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

# Cargar dataset
iris = load_iris()
X = iris.data
y = iris.target

# División train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Modelo
log_reg = LogisticRegression(max_iter=200)
log_reg.fit(X_train, y_train)

# Predicciones
y_pred = log_reg.predict(X_test)

print("Accuracy Iris (LogReg):", accuracy_score(y_test, y_pred))
print("\nReporte de clasificación:\n")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

from sklearn.datasets import load_wine
from sklearn.ensemble import RandomForestClassifier

wine = load_wine()
X_wine = wine.data
y_wine = wine.target

Xw_train, Xw_test, yw_train, yw_test = train_test_split(
    X_wine, y_wine, test_size=0.2, random_state=42, stratify=y_wine
)

rf = RandomForestClassifier(
    n_estimators=200,
    random_state=42
)
rf.fit(Xw_train, yw_train)

yw_pred = rf.predict(Xw_test)

print("Accuracy Wine (RandomForest):", accuracy_score(yw_test, yw_pred))
print("\nReporte de clasificación:\n")
print(classification_report(yw_test, yw_pred, target_names=wine.target_names))

from sklearn.datasets import load_digits
from sklearn.svm import SVC

digits = load_digits()
X_digits = digits.data
y_digits = digits.target

Xd_train, Xd_test, yd_train, yd_test = train_test_split(
    X_digits, y_digits, test_size=0.2, random_state=42, stratify=y_digits
)

svc = SVC(kernel='rbf', gamma='scale')
svc.fit(Xd_train, yd_train)

yd_pred = svc.predict(Xd_test)

print("Accuracy Digits (SVM):", accuracy_score(yd_test, yd_pred))
print("\nReporte de clasificación:\n")
print(classification_report(yd_test, yd_pred))

cm = confusion_matrix(yd_test, yd_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Matriz de confusión - Digits (SVM)")
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.show()

from sklearn.datasets import make_regression
from sklearn.linear_model import LinearRegression

# Dataset sintético
X_reg, y_reg = make_regression(
    n_samples=500,
    n_features=5,
    noise=15,
    random_state=42
)

Xr_train, Xr_test, yr_train, yr_test = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

reg = LinearRegression()
reg.fit(Xr_train, yr_train)

yr_pred = reg.predict(Xr_test)

mse = mean_squared_error(yr_test, yr_pred)
r2 = r2_score(yr_test, yr_pred)

print("MSE (Regresión):", mse)
print("R² (Regresión):", r2)


plt.scatter(yr_test, yr_pred)
plt.xlabel("Valor real")
plt.ylabel("Predicción")
plt.title("Regresión lineal - Valores reales vs predichos")
plt.axline((0, 0), slope=1, linestyle="--")
plt.show()



resumen_modelos = pd.DataFrame([
    {"Modelo": "Iris - Logistic Regression", "Tipo": "Clasificación", "Métrica": "Accuracy", "Valor": accuracy_score(y_test, y_pred)},
    {"Modelo": "Wine - Random Forest",       "Tipo": "Clasificación", "Métrica": "Accuracy", "Valor": accuracy_score(yw_test, yw_pred)},
    {"Modelo": "Digits - SVM",               "Tipo": "Clasificación", "Métrica": "Accuracy", "Valor": accuracy_score(yd_test, yd_pred)},
    {"Modelo": "Regresión sintética - LinReg","Tipo": "Regresión",    "Métrica": "R²",       "Valor": r2}
])

resumen_modelos

     
